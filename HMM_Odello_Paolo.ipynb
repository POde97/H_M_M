{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0099cd6",
   "metadata": {},
   "source": [
    "# Hidden Markov Model: HMM #\n",
    "\n",
    "**Def:** An HMM is a stochastic generator of sequences characterised by:\n",
    "\n",
    "* N states\n",
    "\n",
    "* {$a_{k,j}$} : Transition Probabilities --> $a_{k,j} = P(\\pi(i) = j|\\pi(i-1)=k)$\n",
    "\n",
    "* {$a_{start,k}$} : Initial prob ---> $a_{0,k} = P(\\pi(1)=k)$\n",
    "\n",
    "* {$a_{k,end}$} : Final Probabilities ----> $a_{k,end} = P(\\pi(i)=end|\\pi(i-1)=k)$\n",
    "\n",
    "* An alphabet $C$ with $M$ characters\n",
    "\n",
    "* {$e_k(c)$} : Emission probabilities for each state ---> $e_k(c) = P(s^i = c | \\pi(i) = k)$ \n",
    "\n",
    "where s : sequence , $\\pi$ : path through the states\n",
    "\n",
    "Constraints: \n",
    "\n",
    "$\\sum_k a_{0,k} = 1$\n",
    "\n",
    "$a_{0,k} + \\sum_j a_{k,j} \\forall k$\n",
    "\n",
    "$\\sum_{c \\in C} e_k(c)= 1 $\n",
    "\n",
    "**Joint prob sequence and path** ---> $ P(s,\\pi|M) = P(s|\\pi,M) P(\\pi,M)$ \n",
    "\n",
    "$P(s|\\pi,M) = \\prod_{i=1}^T e_{\\pi(i)}(s^i) $\n",
    "\n",
    "$P(\\pi|M) = a_{0,\\pi(1)} \\prod_{i=2}^T a_{\\pi(i-1) \\pi(i)} a_{\\pi(T),end}$ \n",
    "\n",
    "----> $P(s,\\pi|M) = P(s|\\pi,M) P(\\pi|M) = a_{\\pi(T),end} \\prod_{i=1}^T e_{\\pi(i)}(s^i) a_{\\pi(i-1),\\pi(i)}$\n",
    "\n",
    "\n",
    "\n",
    "**3 MAIN PROBLEM** \n",
    "\n",
    "1) Computing probability of a sequence given the model ---> $P(S|M)$ :  **FORWARD ALGORITHM & BACKWARD ALGORITHM**\n",
    "\n",
    "2) Finding the most probable path given the sequence and the model ---> $\\pi* = argmax_{\\pi} P(\\pi|s,M)$ : **VITERBI**\n",
    "\n",
    "3) Training a model: optimize the transion and emission probabilities : **BAUM-WELCH**\n",
    "\n",
    "\n",
    "**Oss**\n",
    "\n",
    "1) $P(s|M) = \\sum_{\\pi} P(s,\\pi|M)$ and we know $P(s,\\pi|M)$ --> summing over all the path is infeasible \n",
    "\n",
    "2) $\\pi* = argmax_{\\pi} P(\\pi|s,M)$ but $P(\\pi|s,M) = \\frac{P(\\pi,s|M)}{P(s|M)}$ so $P(s|M) \\not\\propto \\pi$ ---> $\\pi* = argmax_{\\pi} P(\\pi,s|M)$\n",
    "\n",
    "\n",
    "\n",
    "**Solution** \n",
    "\n",
    "1) *Forward ALgorithm*: we evaluate $P(s|M)$ in an intellingent way using a good factorization \n",
    "   for each state $K$ and each position $i$ in the sequence compute : $F_k(i) = P(s^1..s^i,\\pi(i)=k|M)$\n",
    "    \n",
    "   Initialization: $F_{BEGIN}(0) = 1$ and $F_{BEGIN,k}(0) = 0$   $\\forall k $\n",
    "    \n",
    "   Recurrence: $F_l(i+1) = P(s^1....s^{i+1},\\pi(i+1) = l) = \\sum_k P(s^1...s^i,\\pi(i)=k) a_{k,l} e_l(s^{i+1}) =                    \\sum_k F_k(i) a_{k,l} e_l(s^{i+1})$\n",
    "    \n",
    "   Termination: $P(s) = P(s^1....s^T,\\pi(T+1) = end) = \\sum_k F_k(T) a_{k,end}$\n",
    "   \n",
    "   *Backward Algorithm*: $B_k(i) = P(s^{i+1}...s^T|\\pi(i)=k) $\n",
    "   \n",
    "   Initialization: $B_k(T) = P(\\pi(T+1)=end|\\pi(T) = k) =a_{k,end}$\n",
    "   \n",
    "   Recurrence $B_l(i-1) = P(s^i...s^T|\\pi(i-1)= l) = \\sum_k P(s^{i+1} ... s^T |\\pi(i) = k )a_{l,k} e_k(s^i) = \\sum_k B_k(i) e_k(s^i) a_{l,k}$\n",
    "   \n",
    "   Termination: $P(S) = P(s^1..s^T|\\pi(0) = BEGIN ) =  \\sum_k P(s^2 ... s^T |\\pi(1) = k )a_{0,k} e_k(s^1) = \\sum_k B_k(1) a_{0,k} e_k(s^1) $\n",
    "   \n",
    "2) *Viterbi* : $V_k(i)$ is the probability of the most probable path for generating the subsequence $s^1...s^i$      ending in the state $k$ at iteration $i$\n",
    "\n",
    "   Initialisation: $V_{BEGIN}(0) = 1 $ and $ V_i(0) = 0$  $ \\forall i \\neq BEGIN$\n",
    "   \n",
    "   Recurrence: $V_l(i+1) = e_l(s^{i+1}) Max_k ( v_k(i) a_{k,l}) $  and  $ ptr_i(l) = argamax_k(V_{k-1}(i) a_{k,l})$\n",
    "   \n",
    "   Termination: $P(s,\\pi*) = Max_k(V_k(T) a_{k,0})$   and     $\\pi*(T) = argmax_k(V_k(T) a_{k0})$\n",
    "               \n",
    "   Traceback : $\\pi*(i-1) = ptr_i(\\pi*(i))$ \n",
    "   \n",
    "   \n",
    "\n",
    "   \n",
    "3) *Baum Welch* : \n",
    "\n",
    "Initialization: start with random parameters \n",
    "    \n",
    "Compute Forward and Backward matrices on the known sequences\n",
    "    \n",
    "Compute $A_{k,l}$ and $E_k(c)$ where:\n",
    "    \n",
    "$A_{k,l} \\sum_i P(\\pi_i = k ,\\pi_{i+1} = l |s) = \\frac{\\sum_i F_k(i) a_{k,l} e_l(s^{i+1}) B_l(i+1)}{P(s)}$\n",
    "    \n",
    "$E_k(c) = \\sum_{s^i = c} P(s^i = c , \\pi= k|s) = \\frac{\\sum_{s^i = c} F_k(i) B_k(i)}{P(s)}$\n",
    "\n",
    "Update: \n",
    "\n",
    "$a_{k,l} = \\frac{A_{k,l}}{\\sum_i^N A_{k,i}}$\n",
    "\n",
    "$e_k(c) = \\frac{E_k(c)}{\\sum_{d \\in C} E_k(d)}$\n",
    "\n",
    "Termination : Has $P(s|M)$ incremented?\n",
    "\n",
    "Yes :Recompute Forward and Backward \n",
    "\n",
    "No : End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02d6294",
   "metadata": {},
   "source": [
    "# HMM building, learning and predicting #\n",
    "\n",
    "Create a HMM using fair and loaded dices. Create your model to predict an unknown model (the provided one).\n",
    "The provided model is:\n",
    "$$\n",
    "Grammar: \\\\\n",
    "Begin \\rightarrow f1 | l1 \\\\\n",
    "l1 \\rightarrow l2 \\\\\n",
    "l2 \\rightarrow l2 | l3 | f1 \\\\\n",
    "l3 \\rightarrow l3 | f1 |end \\\\ \n",
    "f1 \\rightarrow f1 | l1 |end \\\\\n",
    "\\\\\n",
    "labels: \\\\ \n",
    "l1, l2, l3 \\rightarrow loaded-dice (L)\\\\ \n",
    "f1 \\rightarrow fair-die (F)\n",
    "$$\n",
    "\n",
    "1. Write your onw HMM model and use the provided training and the testing sequences (created with with the **base_HMM **)\n",
    "2. Implement Forward and Backward algorithms and train the model using Expectation Maximization: <br>\n",
    "   2.1 Train your model using state labels (Fair/Loaded) and observed sequence (Heads and Tails) <br>\n",
    "   2.2 Train your model using only the observed sequence (Heads/Tails) **[This is optional]** <br>\n",
    "3. Implement a Viterbi and Posterior decoding and compare the predicted labels with the observed labels (Testing), evaluate the Coen's k-score, and other measure of accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "10c7dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "class base_HMM:\n",
    "    def __init__(self, states, state_labels, symbols, a=[], e =[]):\n",
    "        ''' HMM(states, symbols, a=None, e = None)\n",
    "        we assume that first name is begin and last name is end state\n",
    "        we assume to order the state names and the symbols so that a and e are numpy matrices\n",
    "        '''\n",
    "        self.states = states\n",
    "        self.n_states = len(states) #len states è la lunghezza degli stati con Begin e End\n",
    "        self.labels = state_labels\n",
    "        self.n_lab = len(state_labels)\n",
    "        self.symbols = symbols\n",
    "        self.n_symb = len(symbols)\n",
    "        self.a = a\n",
    "        self.e = e\n",
    "        if self.a != []:\n",
    "            self.allowed_tr = np.where(self.a >0,1.0,0)  \n",
    "        else:\n",
    "            self.allowed_tr =  []\n",
    "            \n",
    "    def string_2_vec(self, s, alph):\n",
    "        vector = [[0 if char != letter else 1 for char in alph] for letter in s]\n",
    "        return np.array(vector)\n",
    "    \n",
    "\n",
    "\n",
    "    def init_prob(self, mode=\"random\",epsilon =10**(-10)):\n",
    "        ''' init_prob(mode=\"random\"/ \"uniform\" '''\n",
    "        if mode == \"random\":\n",
    "            a = np.random.uniform(1,100,(self.n_states,self.n_states))\n",
    "            e = np.random.uniform(1,100,(self.n_states,self.n_symb))\n",
    "        else:\n",
    "            a = np.ones((self.n_states,self.n_states))\n",
    "            e = np.ones((self.n_states,self.n_symb))\n",
    "        if self.allowed_tr != []:\n",
    "            a = a * self.allowed_tr\n",
    "        a[:,0] = 0 # no transition to begnin\n",
    "        a[0][-1] = 0 # no trnasition begin to end\n",
    "        a[-1] = 0 # no transitions from end to other states\n",
    "        self.a = a / (a.sum(axis=1)[:,np.newaxis] + epsilon) # normalize\n",
    "        e[0] = 0 # no emissions in begin\n",
    "        e[-1] = 0 # no emissions in end\n",
    "        self.e = e / (e.sum(axis=1)[:,np.newaxis]+ epsilon) # normalize\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x_seq, y_seq=None):\n",
    "        x = self.string_2_vec(x_seq, self.symbols)\n",
    "        y = y_seq \n",
    "        N = len(x)\n",
    "\n",
    "        F = np.zeros((N+2,self.n_states),dtype=np.double)        \n",
    "        # forward initialization\n",
    "        F[0][0] = 1.0\n",
    "        #print(F)\n",
    "        # forward loop\n",
    "        for i in range(1,N+1): # \n",
    "            for s in range(self.n_states): # \n",
    "                #print(s,i)\n",
    "                if y_seq == None or self.labels[s] == y[i-1]: #Masking \n",
    "                    \n",
    "                    for t in range(self.n_states):\n",
    "                        F[i][s] += self.a[t,s]*F[i-1][t]\n",
    "                        \n",
    "                    F[i][s] *= np.dot(self.e[s],x[i-1]) # moltiplico emissione per simbolo, simbolo di fatto è un vettore di zeri e 1\n",
    "                    \n",
    "        s = self.n_states -1  # end state\n",
    "        i = N + 1\n",
    "        for t in range(self.n_states):\n",
    "            F[i][s] += self.a[t,s]*F[i-1][t]\n",
    "        return F\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def backward(self, x_seq, y_seq=None):\n",
    "        x = self.string_2_vec(x_seq, self.symbols)\n",
    "        y = y_seq \n",
    "        N = len(x)\n",
    "        B = np.zeros((N+2,self.n_states),dtype=np.double)        \n",
    "        # Backward initialization\n",
    "        B[-1][-1]=1.0\n",
    "\n",
    "        for t in range(self.n_states):\n",
    "            if y_seq == None or self.labels[t] == y[N-1]:\n",
    "                \n",
    "                B[N][t] = self.a[t,self.n_states-1] \n",
    "        # backward loop\n",
    "        for i in range(N-1,0,-1): # \n",
    "            for s in range(1,self.n_states): # \n",
    "                if y_seq == None or self.labels[s] == y[i-1]: #Masking\n",
    "        \n",
    "                    for t in range(self.n_states):\n",
    "                        B[i][s] += self.a[s,t]*B[i+1][t]*np.dot(self.e[t],x[i])\n",
    "                        \n",
    "                    \n",
    "        s = 0  # end state\n",
    "        i = 0\n",
    "        for t in range(self.n_states):\n",
    "            B[i][s] += self.a[s,t]*B[i+1][t]*np.dot(self.e[t],x[0])\n",
    "        return B\n",
    "    \n",
    "#################################################################################################################    \n",
    "    \n",
    "    def viterbi(self,x_seq):\n",
    "        hidden_gramatical_pi_str=[]\n",
    "        labels_pi_str=[]\n",
    "        x = self.string_2_vec(x_seq, self.symbols)\n",
    "        N=len(x)\n",
    "        v = np.zeros((N+2,self.n_states))\n",
    "        ptr = np.zeros((self.n_states,N+1))\n",
    "        pi_star = np.zeros(N)\n",
    "        #inizializzazione \n",
    "        v[0][0]=1.0\n",
    "        max_v = 0\n",
    "        argmax =0\n",
    "        max_index = 0\n",
    "        #Ricorrenza\n",
    "        for i in range(1,N+1): # \n",
    "            for s in range(self.n_states):\n",
    "                max_index = 0\n",
    "                max_v = 0\n",
    "                argmax =0\n",
    "                #calcolo max\n",
    "                for t in range(self.n_states):\n",
    "                    temp_v = max_v\n",
    "                    max_v = v[i-1][t]*self.a[t,s]\n",
    "                    if max_v > temp_v:\n",
    "                        argmax = max_v\n",
    "                        max_index = t\n",
    "                v[i][s] = np.dot(self.e[s],x[i-1])*argmax\n",
    "                ptr[s][i] = max_index\n",
    "        \n",
    "        maxx = 0.  \n",
    "        max_ind = 0\n",
    "        P=0.\n",
    "        mazz = 0.\n",
    "        #Termination---> Final state = self.n_states-1\n",
    "        for j in range(self.n_states):\n",
    "            temp = maxx\n",
    "            maxx = v[N][j]*self.a[j,self.n_states-1]\n",
    "            #print(\"deb1\",maxx)#maxx -> probabilità di ogni sequenza\n",
    "            if maxx > temp:\n",
    "                mazz = maxx\n",
    "                max_ind = j\n",
    "        v[N+1][self.n_states-1] = mazz #mazz -> probabilità sequenza più probabile\n",
    "        #print('deb2',mazz)\n",
    "        pi_star[N-1] = max_ind\n",
    "        hidden_gramatical_pi_str.append(self.states[max_ind])\n",
    "        labels_pi_str.append(self.labels[max_ind])\n",
    "        for i in range(N-1,0,-1):\n",
    "            pi_star[i-1] = ptr[int(pi_star[i])][i+1]\n",
    "            hidden_gramatical_pi_str.insert(0,self.states[int(pi_star[i-1])])\n",
    "            labels_pi_str.insert(0,self.labels[int(pi_star[i-1])])\n",
    "        return hidden_gramatical_pi_str,labels_pi_str  #pi_star\n",
    "    \n",
    "    \n",
    "################################################################################################################## \n",
    "    \n",
    "    \n",
    "    \n",
    "    def posterior_decoding(self,x_seq,y=None):\n",
    "        \n",
    "        posterior_index = []\n",
    "        labels_posterior_str=[]\n",
    "        hidden_gramatical_posterior_str = []\n",
    "        N=len(x_seq)\n",
    "        F = self.forward(x_seq,y)  \n",
    "        B = self.backward(x_seq,y)\n",
    "        \n",
    "        for i in range(1,N+1):\n",
    "            idx = []\n",
    "            idx = [F[i][k] * B[i][k] /F[-1][-1] for k in range(self.n_states)]\n",
    "            max_ind=np.argmax(idx)\n",
    "            posterior_index.append(max_ind)\n",
    "            hidden_gramatical_posterior_str.append(self.states[max_ind])\n",
    "            labels_posterior_str.append(self.labels[max_ind])\n",
    "            \n",
    "        return hidden_gramatical_posterior_str,labels_posterior_str\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def baumwelch_Nseq(self,X_train,y_seq=None):\n",
    "        n_iter=10000\n",
    "        temp_p =0.\n",
    "        # inizializzo randomicamente a,e \n",
    "        self.init_prob( mode=\"random\",epsilon =10**(-10))\n",
    "        \n",
    "        for iteration in range(n_iter):\n",
    "            #Inizializzazione A,E\n",
    "            A = np.zeros((self.n_states,self.n_states),dtype=np.double)\n",
    "            E = np.zeros((self.n_states,self.n_symb),dtype=np.double)\n",
    "            A_totseq = np.zeros((self.n_states,self.n_states),dtype=np.double)\n",
    "            E_totseq = np.zeros((self.n_states,self.n_symb),dtype=np.double)\n",
    "            P_s = 0.\n",
    "\n",
    "            for seq in range(len(X_train)):\n",
    "                x_seq = X_train[seq]\n",
    "                if y_seq==None:\n",
    "                    y = y_seq\n",
    "                else:\n",
    "                    y = y_seq[seq]\n",
    "                x = self.string_2_vec(x_seq, self.symbols)\n",
    "                N = len(x)\n",
    "                #F , B per ogni sequenza \n",
    "                F = self.forward(x_seq,y) #sequence \n",
    "                B = self.backward(x_seq,y) #sequence \n",
    "\n",
    "            #Expected number of transitions A per sequence \n",
    "                for k in range(1,self.n_states):\n",
    "                    num =0.\n",
    "                    for t in range(N+1):\n",
    "                        num += F[t][0]*self.a[0,k]*B[t+1][k] #no emissione \n",
    "                    A[0][k] = num/F[-1][-1]\n",
    "                        \n",
    "                for i in range(1,self.n_states):\n",
    "                    for k in range(1,self.n_states):\n",
    "                        num=0.\n",
    "                        for t in range(N):\n",
    "                            num += F[t][i] * self.a[i,k] * np.dot(self.e[k],x[t]) * B[t+1][k]\n",
    "            \n",
    "                        A[i][k] = num/(F[-1][-1])\n",
    "            \n",
    "                for k in range(1,self.n_states):\n",
    "                    num = 0.\n",
    "                    for t in range(N+1):\n",
    "                        num += F[t][k]*self.a[k,-1]*B[t+1][-1] #no emissione\n",
    "                    A[k][-1] = num/F[-1][-1]\n",
    "            \n",
    "            #Expected number of emission per sequence \n",
    "                for k in range(1,self.n_states):\n",
    "                    for c in range(self.n_symb):\n",
    "                        num = 0.\n",
    "                        for t in range(1,N+1):\n",
    "                            if x[t-1][c]==1:\n",
    "                                num += F[t][k]*B[t][k]\n",
    "                        E[k][c] = num/F[-1][-1]\n",
    "            \n",
    "            #Sommo su su tutte le sequenze A e E \n",
    "                for j in range(self.n_states):\n",
    "                    for t in range(self.n_states):\n",
    "                        A_totseq[j][t] += A[j][t]\n",
    "                        \n",
    "                for j in range(self.n_states):\n",
    "                    for c in range(self.n_symb):\n",
    "                        E_totseq[j][c] += E[j][c]\n",
    "                             \n",
    "                P_s += F[-1][-1]\n",
    "                \n",
    "            \n",
    "            A = A_totseq\n",
    "            E = E_totseq\n",
    "            P_s = P_s/len(X_train)\n",
    "\n",
    "            #Ricostruisco prob_tranisizion e emission\n",
    "            for k in range(1,self.n_states-1):\n",
    "                for l in range(1,self.n_states):\n",
    "                    den = 0.\n",
    "                    for i in range(1,self.n_states):\n",
    "                        #print(\"k\",k,\"i\",i)\n",
    "                        den += A[k][i]\n",
    "\n",
    "                    self.a[k][l]=A[k][l]/den\n",
    "\n",
    "            for k in range(1,self.n_states-1):\n",
    "                for c in range(self.n_symb):\n",
    "                    den =0.\n",
    "                    for d in range(self.n_symb):\n",
    "                        den += E[k][d]\n",
    "\n",
    "                    self.e[k][c] = E[k][c]/den\n",
    "                    \n",
    "            #media delle probilità di P(S|M) per ogni sequenza come condizione di uscita \n",
    "            if P_s<=temp_p:\n",
    "                #print(temp_p,P_s)\n",
    "                break \n",
    "            else:\n",
    "                temp_p = P_s\n",
    "\n",
    "\n",
    "        return self.a,self.e,iteration\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "######################################################################################################################    \n",
    "    \n",
    "    \n",
    "    def random_path(self, min_len=10):\n",
    "        hp, hlab, op = [], [], []\n",
    "        hp.append(self.states[0])\n",
    "        hlab.append(self.labels[0])\n",
    "        op=[None]\n",
    "        cs = 0\n",
    "        i = 0\n",
    "        while i< min_len:\n",
    "            new_state = np.random.choice(range(1,self.n_states),1,p=self.a[cs][1:])[0]\n",
    "            if self.states[new_state] != self.states[-1]:\n",
    "                cs = new_state\n",
    "                hp.append(self.states[cs])\n",
    "                hlab.append(self.labels[cs])\n",
    "                symb = np.random.choice(range(self.n_symb),1,p=self.e[cs])[0]\n",
    "                op.append(self.symbols[symb])\n",
    "                i +=1\n",
    "        while self.states[new_state] != self.states[-1]:\n",
    "            new_state = np.random.choice(range(1,self.n_states),1,p=self.a[cs][1:])[0]\n",
    "            if self.states[new_state] != self.states[-1]:\n",
    "                cs = new_state\n",
    "                hp.append(self.states[cs])\n",
    "                hlab.append(self.labels[cs])\n",
    "                symb = np.random.choice(range(self.n_symb),1,p=self.e[cs])[0]\n",
    "                op.append(self.symbols[symb])\n",
    "        return hp, hlab, op\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae24e7eb",
   "metadata": {},
   "source": [
    "**Esempio appunti**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d0b7b7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-103-7dd0aaec10d1>:18: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if self.a != []:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transitions=np.array([ [0, 0.2, 0.8, 0],\n",
    "                       [0, 0.7, 0.2, 0.1],\n",
    "                       [0, 0.1, 0.8, 0.1],\n",
    "                       [0, 0,   0,   0],\n",
    "                     ])\n",
    "\n",
    "#create a model\n",
    "#EMISSIONS A-C-G-T\n",
    "emissions = np.array([ [0, 0, 0, 0], [0.1, 0.4, 0.4, 0.1], [0.25, 0.25, 0.25, 0.25], [0, 0, 0, 0] ])\n",
    "hmm = base_HMM([\"begin\",\"Y\",\"N\",\"end\"],[\"-\",\"Y\",\"N\",\"-\"], [\"A\",\"C\", \"G\", \"T\"], a=transitions, e=emissions )    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e99ff6",
   "metadata": {},
   "source": [
    "**Viterbi Decoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "051eda93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.viterbi(\"AGCGCGTAATCTG\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf67037d",
   "metadata": {},
   "source": [
    "**Posterior Decoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "269ba858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N', 'N', 'N', 'Y', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.posterior_decoding(\"AGCGCGTAATCTG\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9fb05",
   "metadata": {},
   "source": [
    "**Esempio compito**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "471b0f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-103-7dd0aaec10d1>:18: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if self.a != []:\n"
     ]
    }
   ],
   "source": [
    "transitions = np.array([[0., 0.30,   0,   0, 0.7,      0.],\n",
    "                           [0.,    0, 1.0,   0,   0,       0.],\n",
    "                           [0.,    0, 0.05, 0.90,  0.05,   0.],\n",
    "                           [0.,    0.,   0, 0.6, 0.3,      0.1], \n",
    "                           [0.,    0.1,   0., 0, 0.8,      0.1],\n",
    "                           [0.,    0,   0,   0,   0,       0]],dtype=np.double)\n",
    "        \n",
    "    \n",
    "    #create a model         #il begin non emette nulla                              end non emette nulla \n",
    "emissions = np.array([ [0, 0], [0.2, 0.8], [0.2, 0.8], [0.2, 0.8], [0.5, 0.5], [0, 0] ])\n",
    "hmm = base_HMM([\"begin\",\"l1\",\"l2\",\"l3\",\"f1\",\"end\"],[\"-\",\"L\",\"L\",\"L\",\"F\",\"-\"], [\"H\",\"T\"], a=transitions, e=emissions )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4be9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkset(N,hmm, ml):\n",
    "    X, y =[], []\n",
    "    for n in range(N):\n",
    "        states, state_labels, observed = hmm.random_path(ml)\n",
    "        X.append(\"\".join(observed[1:])) \n",
    "        y.append(\"\".join(state_labels[1:]))\n",
    "    return X,y\n",
    "\n",
    "Ntr = 100  # set this eg. 100 or 1000\n",
    "Nts = 100  # set this eg. 100\n",
    "min_seq_len = 50 # set this 10 or 50 or 100\n",
    "X_train, y_train = mkset(Ntr,hmm, min_seq_len) \n",
    "X_test, y_test = mkset(Nts,hmm, min_seq_len) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc962613",
   "metadata": {},
   "source": [
    "**Training Supervised**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4afe585b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-9e9812506e10>:37: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if self.allowed_tr != []:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.00000000e+00, 5.59657104e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "         4.40342896e-01, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 6.42145670e-01, 2.93897928e-01,\n",
       "         6.39564023e-02, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.54014174e-13,\n",
       "         9.45711463e-01, 5.42885373e-02],\n",
       "        [0.00000000e+00, 1.10208228e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "         8.69730828e-01, 2.00609446e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]]),\n",
       " array([[0.        , 0.        ],\n",
       "        [0.18046709, 0.81953291],\n",
       "        [0.22383721, 0.77616279],\n",
       "        [0.17938585, 0.82061415],\n",
       "        [0.49492128, 0.50507872],\n",
       "        [0.        , 0.        ]]),\n",
       " 661)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.baumwelch_Nseq(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a0600a",
   "metadata": {},
   "source": [
    "**Training Unsupervised**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53ef7d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-9e9812506e10>:37: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if self.allowed_tr != []:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.00000000e+00, 4.45953724e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "         5.54046276e-01, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 7.16646895e-01, 1.37780131e-01,\n",
       "         1.45572974e-01, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 9.65810675e-01,\n",
       "         1.13974279e-03, 3.30495818e-02],\n",
       "        [0.00000000e+00, 8.05863731e-02, 0.00000000e+00, 0.00000000e+00,\n",
       "         9.19413627e-01, 1.75565022e-90],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "         0.00000000e+00, 0.00000000e+00]]),\n",
       " array([[0.        , 0.        ],\n",
       "        [0.11845897, 0.88154103],\n",
       "        [0.11018183, 0.88981817],\n",
       "        [0.4118994 , 0.5881006 ],\n",
       "        [0.4917217 , 0.5082783 ],\n",
       "        [0.        , 0.        ]]),\n",
       " 2506)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm.baumwelch_Nseq(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207b86e",
   "metadata": {},
   "source": [
    "**Cohen Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f2275b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viterbi Cohen Score :  0.07644063483642555        Posterior Cohen Score :  0.22729770681767048\n"
     ]
    }
   ],
   "source": [
    "vit_cohen=[]\n",
    "post_cohen=[]\n",
    "for i in range(len(X_train)):\n",
    "    viterbi_path=hmm.viterbi(X_train[i])[1]\n",
    "    posterior_path = hmm.posterior_decoding(X_train[i])[1]\n",
    "    true_sequence = y_train[i]\n",
    "               \n",
    "    cohen_viterbi=[]\n",
    "    cohen_posterior=[]\n",
    "    cohen_true=[]\n",
    "    for i in viterbi_path:\n",
    "        if i =='L':\n",
    "            cohen_viterbi.append(0)\n",
    "        else:\n",
    "            cohen_viterbi.append(1)\n",
    "\n",
    "    for i in posterior_path:\n",
    "        if i =='L':\n",
    "            cohen_posterior.append(0)\n",
    "        else:\n",
    "            cohen_posterior.append(1)\n",
    "        \n",
    "\n",
    "    for i in true_sequence:\n",
    "        if i =='L':\n",
    "            cohen_true.append(0)\n",
    "        else:\n",
    "            cohen_true.append(1)\n",
    "               \n",
    "    vit_cohen.append(cohen_kappa_score(cohen_viterbi,cohen_true))\n",
    "    post_cohen.append(cohen_kappa_score(cohen_posterior,cohen_true))\n",
    "               \n",
    "print('Viterbi Cohen Score : ',np.mean(vit_cohen),'       Posterior Cohen Score : ',np.mean(post_cohen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218a713",
   "metadata": {},
   "source": [
    "**oss**  Il posterior ha un Cohen score più alto però non preserva la grammatica!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6fd414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
